# 高性能负数匹蓝优化方案（千万级数据量）

鉴于您提供的千万级数据量（890万行蓝票 vs 67万行负数），原有的单线程贪心算法将面临严重的性能瓶颈。本方案采用 **“内存计算 + 向量化过滤 + 分布式并行”** 的架构，旨在将处理时间从“数天”缩短至“分钟级”。

------

## 1. 核心瓶颈分析与对策

| **瓶颈点**   | **原有逻辑风险**          | **优化对策**                                                 | **技术栈/工具**           |
| ------------ | ------------------------- | ------------------------------------------------------------ | ------------------------- |
| **IO 延迟**  | 逐行查询 DB，67万次网络IO | **全量预加载**：一次性读取所有相关数据到内存。               | `Polars` / `DuckDB`       |
| **计算速度** | Python `Decimal` 循环慢   | **向量化 & 整数化**：使用 int64 替代 Decimal 进行核心匹配运算。 | `NumPy` / `Cython`        |
| **搜索空间** | 在 890万行中搜索          | **哈希分片**：按商品+税率切分为数千个小池子，互不干扰。      | `Dictionary Partitioning` |
| **单核限制** | Python GIL 锁限制 CPU     | **多进程并行**：利用多核 CPU 同时处理不同的商品组。          | `multiprocessing`         |

------

## 2. 数据库层优化 (PostgreSQL)

在数据量达到千万级时，数据库不仅是存储，更是第一道过滤器。

### 2.1 覆盖索引 (Covering Index)

这是最关键的优化。我们不仅需要索引来查找，更需要索引直接提供数据，避免“回表”读取磁盘。

SQL

```
-- 针对蓝票明细表的极致优化索引
-- 目的：按销方、购方、商品、税率快速分组，并按金额降序供给贪心算法
CREATE INDEX CONCURRENTLY idx_blue_supply_optim 
ON t_sim_vatinvoice_item_1201 (
    fsalertaxno,      -- 销方税号（第一层过滤）
    fbuyertaxno,      -- 购方税号（第二层过滤）
    fspbm,            -- 商品编码（分组键）
    ftaxrate,         -- 税率（分组键）
    fitemremainredamount DESC -- 剩余金额降序（贪心算法优化）
) 
INCLUDE (
    fentryid, 
    funitprice, 
    fitemremainrednum, 
    fitemremainredtax
);

-- 针对负数单据的索引
CREATE INDEX CONCURRENTLY idx_neg_demand_optim 
ON t_sim_original_bill_item_1201 (
    fsalertaxno, 
    fbuyertaxno, 
    fspbm, 
    ftaxrate
);
```

### 2.2 数据预取 SQL

不要使用 ORM 的对象加载，直接使用 `COPY` 或极速 SQL 读取。

SQL

```
SELECT 
    fentryid, fspbm, ftaxrate, 
    -- 将金额转换为“分”或更小单位的整数，避免浮点传输
    (fitemremainredamount * 10000)::bigint as amount_scaled, 
    fitemremainrednum, funitprice
FROM t_sim_vatinvoice_item_1201
WHERE fsalertaxno = '...' AND fbuyertaxno = '...' 
  AND fitemremainredamount > 0; -- 仅读取有余额的蓝票
```

------

## 3. 算法层实现 (Python + Polars + Multiprocessing)

我们使用 `Polars` 库，它比 Pandas 快得多，且对内存更友好。

### 3.1 完整优化代码结构

Python

```
import polars as pl
import numpy as np
from multiprocessing import Pool, cpu_count
from decimal import Decimal, getcontext
from collections import defaultdict

# 设置高精度上下文，用于最终校验
getcontext().prec = 28

class FastMatcher:
    def __init__(self, connection_str):
        self.conn_str = connection_str
        # 放大因子，将金额转为整数计算，兼顾精度
        # 数据库是 10位小数，这里放大 10^4 或更高，视具体需求
        self.SCALE_FACTOR = 10000 

    def load_data(self, seller_tax_no, buyer_tax_no):
        """
        使用 Polars 高速加载数据
        """
        print("Loading data...")
        
        # 1. 加载蓝票 (Supply)
        # 注意：这里直接读库，Polars 支持 read_database
        q_blue = f"""
            SELECT fentryid, fspbm, ftaxrate, 
                   (fitemremainredamount * {self.SCALE_FACTOR})::bigint as amt_scaled,
                   fitemremainredamount as amt_orig,
                   fitemremainrednum, funitprice
            FROM t_sim_vatinvoice_item_1201
            WHERE fsalertaxno = '{seller_tax_no}' 
              AND fbuyertaxno = '{buyer_tax_no}'
              AND fitemremainredamount > 0
        """
        self.df_blue = pl.read_database(q_blue, self.conn_str)

        # 2. 加载负数 (Demand)
        q_neg = f"""
            SELECT fentryid, fspbm, ftaxrate, 
                   (famount * {self.SCALE_FACTOR})::bigint as amt_scaled,
                   famount as amt_orig
            FROM t_sim_original_bill_item_1201
            WHERE fsalertaxno = '{seller_tax_no}' 
              AND fbuyertaxno = '{buyer_tax_no}'
              -- 假设已过滤出未处理的单据
        """
        self.df_neg = pl.read_database(q_neg, self.conn_str)
        
        print(f"Loaded {len(self.df_blue)} blue lines, {len(self.df_neg)} negative lines.")

    def partition_data(self):
        """
        数据分片：按 (商品, 税率) 将数据拆分
        返回一个列表，每个元素是一个独立的匹配任务
        """
        # 获取所有唯一的 (商品, 税率) 组合
        # 仅保留在负数表中存在的组合
        groups = self.df_neg.select(['fspbm', 'ftaxrate']).unique()
        
        tasks =
        for row in groups.iter_rows():
            spbm, rate = row
            
            # 过滤出当前组的数据
            # Polars 的 filter 非常快
            blues = self.df_blue.filter(
                (pl.col('fspbm') == spbm) & (pl.col('ftaxrate') == rate)
            ).sort('amt_scaled', descending=True) # 预排序，利于贪心
            
            negs = self.df_neg.filter(
                (pl.col('fspbm') == spbm) & (pl.col('ftaxrate') == rate)
            ).sort('amt_scaled', descending=True)
            
            if not blues.is_empty() and not negs.is_empty():
                tasks.append((blues, negs))
                
        return tasks

    @staticmethod
    def solve_group(args):
        """
        核心匹配逻辑 - 静态方法以便多进程调用
        """
        df_blue, df_neg = args
        matches =
        
        # 将 Polars DataFrame 转为 Numpy 数组，极致速度
        # 结构: [id, scaled_amount, orig_amount,...]
        blue_arr = df_blue.select(['fentryid', 'amt_scaled']).to_numpy()
        # 变为可变数组，因为要扣减余额
        blue_ids = blue_arr[:, 0]
        blue_amts = blue_arr[:, 1].astype(np.int64)
        
        neg_rows = df_neg.iter_rows(named=True)
        
        # 简单的贪心算法 (Best Fit Decreasing) 
        # 在 C++ 中这叫 Bin Packing
        for neg in neg_rows:
            demand = neg['amt_scaled']
            neg_id = neg['fentryid']
            
            # 1. 尝试精确匹配 (Exact Match)
            # numpy searchsorted or simple `where`
            exact_indices = np.where(blue_amts == demand)
            if len(exact_indices) > 0:
                idx = exact_indices
                matches.append({
                    'neg_id': neg_id, 'blue_id': blue_ids[idx], 
                    'alloc_amt': demand
                })
                blue_amts[idx] = 0
                continue
                
            # 2. 贪心填坑 (Greedy Fill)
            # 遍历所有可用蓝票（已按降序排列）
            # 对于 900万行级别，这里可以优化为二分查找或跳表
            # 但由于已经分片，每个组内的蓝票数量通常不多 (<10000)，线性扫描即可
            
            current_demand = demand
            
            # 向量化查找所有 > 0 的索引
            valid_indices = np.where(blue_amts > 0)
            
            for idx in valid_indices:
                supply = blue_amts[idx]
                if supply >= current_demand:
                    # 蓝票够吃，吃掉部分，结束
                    matches.append({
                        'neg_id': neg_id, 'blue_id': blue_ids[idx], 
                        'alloc_amt': current_demand
                    })
                    blue_amts[idx] -= current_demand
                    current_demand = 0
                    break
                else:
                    # 蓝票不够，全吃掉，继续找下一个
                    matches.append({
                        'neg_id': neg_id, 'blue_id': blue_ids[idx], 
                        'alloc_amt': supply
                    })
                    current_demand -= supply
                    blue_amts[idx] = 0
            
            if current_demand > 0:
                # 记录缺量异常
                matches.append({'neg_id': neg_id, 'error': 'Insufficient Supply'})
                
        return matches

    def run_parallel(self):
        tasks = self.partition_data()
        print(f"Created {len(tasks)} independent matching tasks.")
        
        # 开启进程池
        # 建议进程数 = CPU 核心数 - 1
        with Pool(processes=cpu_count() - 1) as pool:
            results = pool.map(self.solve_group, tasks)
            
        # 合并结果
        final_matches = [m for group_res in results for m in group_res]
        return final_matches

# 使用示例
# matcher = FastMatcher("postgresql://user:pass@localhost/db")
# matcher.load_data('SellerX', 'BuyerY')
# results = matcher.run_parallel()
```

------

## 4. 尾差校验的性能陷阱与优化

您提到的“尾差校验”（Tail Difference Check）是性能杀手，因为它涉及浮点反算。

优化策略：不要在匹配循环中做严格校验。

1. **两阶段法 (Two-Phase approach)**：
   - **Phase 1 (快速匹配)**：如上代码所示，完全基于“金额整数”进行匹配。假设所有匹配都是合法的。这一步极快。
   - **Phase 2 (延迟校验)**：匹配完成后，仅对生成的 `(负数行, 蓝票行, 分配金额)` 结果集进行尾差校验。
2. **成功率预估**：
   - 绝大多数“整额”或“大额”匹配天然满足尾差。
   - 只有当 `分配金额 / 蓝票单价` 产生无限循环小数时（如 $10 \div 3$），才容易出问题。
3. **失败回退**：
   - 在 Phase 2 中，如果某条匹配校验失败（概率极低），则将该负数行标记为“难搞”，回退到特殊的**慢速处理队列**，仅对这 1% 的数据进行复杂的带校验搜索。这比对 100% 的数据都做校验要快得多。

## 5. 总结

应对 890万 vs 67万 的数据量，核心不在于算法的精妙（如动态规划），而在于**工程架构**：

1. **内存为王**：Polars 全量加载，消灭 99% 的 SQL IO。
2. **分而治之**：按商品编码切分，将“大数据”变成 5000 个“小数据”并行处理。
3. **整数先行**：用 Int64 跑通主流程，把昂贵的 Decimal 校验推迟到最后一步。

这套方案可以在普通 16核/32G 服务器上，将匹配过程控制在 **5-15分钟** 内。